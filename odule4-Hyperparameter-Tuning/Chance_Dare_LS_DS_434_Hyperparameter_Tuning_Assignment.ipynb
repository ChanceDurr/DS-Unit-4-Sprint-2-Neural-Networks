{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chance Dare LS_DS_434_Hyperparameter_Tuning_Assignment.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChanceDurr/DS-Unit-4-Sprint-2-Neural-Networks/blob/master/odule4-Hyperparameter-Tuning/Chance_Dare_LS_DS_434_Hyperparameter_Tuning_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9Ryp-TVm4njD"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "\n",
        "# Hyperparameter Tuning\n",
        "\n",
        "## *Data Science Unit 4 Sprint 2 Assignment 4*\n",
        "\n",
        "## Your Mission, should you choose to accept it...\n",
        "\n",
        "To hyperparameter tune and extract every ounce of accuracy out of this telecom customer churn dataset: <https://drive.google.com/file/d/1dfbAsM9DwA7tYhInyflIpZnYs7VT-0AQ/view> \n",
        "\n",
        "## Requirements\n",
        "\n",
        "- Load the data\n",
        "- Clean the data if necessary (it will be)\n",
        "- Create and fit a baseline Keras MLP model to the data.\n",
        "- Hyperparameter tune (at least) the following parameters:\n",
        " - batch_size\n",
        " - training epochs\n",
        " - optimizer\n",
        " - learning rate (if applicable to optimizer)\n",
        " - momentum (if applicable to optimizer)\n",
        " - activation functions\n",
        " - network weight initialization\n",
        " - dropout regularization\n",
        " - number of neurons in the hidden layer\n",
        " \n",
        " You must use Grid Search and Cross Validation for your initial pass of the above hyperparameters\n",
        " \n",
        " Try and get the maximum accuracy possible out of this data! You'll save big telecoms millions! Doesn't that sound great?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hwaKda8LSAq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "import tensorflow\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "import wandb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jCq-CwvUKqh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9704ccb7-7996-42b1-9664-16f74b74bad4"
      },
      "source": [
        "pip install wandb"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wandb\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3e/f0/c0d690d66be181ac74624fda68a53e3daf3008cf1a10702b957bf0a08420/wandb-0.8.9-py2.py3-none-any.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 9.2MB/s \n",
            "\u001b[?25hCollecting shortuuid>=0.5.0 (from wandb)\n",
            "  Downloading https://files.pythonhosted.org/packages/80/d7/2bfc9332e68d3e15ea97b9b1588b3899ad565120253d3fd71c8f7f13b4fe/shortuuid-0.5.0.tar.gz\n",
            "Collecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading https://files.pythonhosted.org/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (1.12.0)\n",
            "Requirement already satisfied: Click>=7.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (7.0)\n",
            "Collecting watchdog>=0.8.3 (from wandb)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/e3/5a55d48a29300160779f0a0d2776d17c1b762a2039b36de528b093b87d5b/watchdog-0.9.0.tar.gz (85kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 28.7MB/s \n",
            "\u001b[?25hCollecting python-dateutil>=2.6.1 (from wandb)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/17/c62faccbfbd163c7f57f3844689e3a78bae1f403648a6afb1d0866d87fbb/python_dateutil-2.8.0-py2.py3-none-any.whl (226kB)\n",
            "\u001b[K     |████████████████████████████████| 235kB 39.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (2.21.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (5.4.8)\n",
            "Collecting sentry-sdk>=0.4.0 (from wandb)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2c/02/313e94836ff56e4bec0e7343a1fcff6f3aa2d4a61b703d641e61bb0f306a/sentry_sdk-0.11.2-py2.py3-none-any.whl (81kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 25.0MB/s \n",
            "\u001b[?25hCollecting GitPython>=1.0.0 (from wandb)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8e/c7/70bd352e8a561a9b6d1cde9aa313b9d7c871b0c94c3821f44c01f3187e1d/GitPython-3.0.2-py3-none-any.whl (453kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 42.8MB/s \n",
            "\u001b[?25hCollecting subprocess32>=3.5.3 (from wandb)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/c8/564be4d12629b912ea431f1a50eb8b3b9d00f1a0b1ceff17f266be190007/subprocess32-3.5.4.tar.gz (97kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 29.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (7.352.0)\n",
            "Collecting gql>=0.1.0 (from wandb)\n",
            "  Downloading https://files.pythonhosted.org/packages/aa/9c/2933b7791210e00f5c26a6243198cc03af9132c29cf85e4c22cb007f171e/gql-0.1.0.tar.gz\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.6/dist-packages (from watchdog>=0.8.3->wandb) (3.13)\n",
            "Collecting argh>=0.24.1 (from watchdog>=0.8.3->wandb)\n",
            "  Downloading https://files.pythonhosted.org/packages/06/1c/e667a7126f0b84aaa1c56844337bf0ac12445d1beb9c8a6199a7314944bf/argh-0.26.2-py2.py3-none-any.whl\n",
            "Collecting pathtools>=0.1.1 (from watchdog>=0.8.3->wandb)\n",
            "  Downloading https://files.pythonhosted.org/packages/e7/7f/470d6fcdf23f9f3518f6b0b76be9df16dcc8630ad409947f8be2eb0ed13a/pathtools-0.1.2.tar.gz\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->wandb) (2019.6.16)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->wandb) (2.8)\n",
            "Collecting gitdb2>=2.0.0 (from GitPython>=1.0.0->wandb)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/da/30/a407568aa8d8f25db817cf50121a958722f3fc5f87e3a6fba1f40c0633e3/gitdb2-2.0.5-py2.py3-none-any.whl (62kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 23.6MB/s \n",
            "\u001b[?25hCollecting graphql-core>=0.5.0 (from gql>=0.1.0->wandb)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6a/11/bc4a7eb440124271289d93e4d208bd07d94196038fabbe2a52435a07d3d3/graphql_core-2.2.1-py2.py3-none-any.whl (250kB)\n",
            "\u001b[K     |████████████████████████████████| 256kB 47.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: promise>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from gql>=0.1.0->wandb) (2.2.1)\n",
            "Collecting smmap2>=2.0.0 (from gitdb2>=2.0.0->GitPython>=1.0.0->wandb)\n",
            "  Downloading https://files.pythonhosted.org/packages/55/d2/866d45e3a121ee15a1dc013824d58072fd5c7799c9c34d01378eb262ca8f/smmap2-2.0.5-py2.py3-none-any.whl\n",
            "Collecting rx<3,>=1.6 (from graphql-core>=0.5.0->gql>=0.1.0->wandb)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/33/0f/5ef4ac78e2a538cc1b054eb86285fe0bf7a5dbaeaac2c584757c300515e2/Rx-1.6.1-py2.py3-none-any.whl (179kB)\n",
            "\u001b[K     |████████████████████████████████| 184kB 48.7MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: shortuuid, watchdog, subprocess32, gql, pathtools\n",
            "  Building wheel for shortuuid (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for shortuuid: filename=shortuuid-0.5.0-cp36-none-any.whl size=5499 sha256=5feff43f68235e61e8f39cd8114aac0f42e5594f9aaafebae22b961be5051f1b\n",
            "  Stored in directory: /root/.cache/pip/wheels/3f/eb/fd/69e5177f67b505e44acbd1aedfbe44b91768ee0c4cd5636576\n",
            "  Building wheel for watchdog (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for watchdog: filename=watchdog-0.9.0-cp36-none-any.whl size=73652 sha256=207377885290d1e79feff4fd286979fcfac420a47b9b68b6801a2e4b04147dbd\n",
            "  Stored in directory: /root/.cache/pip/wheels/61/1d/d0/04cfe495619be2095eb8d89a31c42adb4e42b76495bc8f784c\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for subprocess32: filename=subprocess32-3.5.4-cp36-none-any.whl size=6489 sha256=6e760522e4e0018d15a1aa91d32bf954e20688ce90ab181b1110e270ee56b86f\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/39/1a/5e402bdfdf004af1786c8b853fd92f8c4a04f22aad179654d1\n",
            "  Building wheel for gql (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gql: filename=gql-0.1.0-cp36-none-any.whl size=5541 sha256=b714c46ff7fcc377ac81f4b278d67991b85ccc3b8400d5e52a8e7169511155ef\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/8d/65/a3247f500d675d80a01e4d2f0ee44fe99f1faef575bc2a1664\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-cp36-none-any.whl size=8786 sha256=b42d3182afaa4cb76cfcf58e7a2f27d2a739f163e9e2fd8febc1ea4f99b307da\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/04/79/c3b0c3a0266a3cb4376da31e5bfe8bba0c489246968a68e843\n",
            "Successfully built shortuuid watchdog subprocess32 gql pathtools\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: shortuuid, docker-pycreds, argh, pathtools, watchdog, python-dateutil, sentry-sdk, smmap2, gitdb2, GitPython, subprocess32, rx, graphql-core, gql, wandb\n",
            "  Found existing installation: python-dateutil 2.5.3\n",
            "    Uninstalling python-dateutil-2.5.3:\n",
            "      Successfully uninstalled python-dateutil-2.5.3\n",
            "Successfully installed GitPython-3.0.2 argh-0.26.2 docker-pycreds-0.4.0 gitdb2-2.0.5 gql-0.1.0 graphql-core-2.2.1 pathtools-0.1.2 python-dateutil-2.8.0 rx-1.6.1 sentry-sdk-0.11.2 shortuuid-0.5.0 smmap2-2.0.5 subprocess32-3.5.4 wandb-0.8.9 watchdog-0.9.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "dateutil"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jP1ZbAyiUPa7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "dcab3fa2-9f7d-4f20-cd4c-7e9b8f500cc0"
      },
      "source": [
        "!wandb login"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "You can find your API keys in your browser here: https://app.wandb.ai/authorize\n",
            "Paste an API key from your profile: 432628d0c1492caac81ba34f619843052f94b04b\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[32mSuccessfully logged in to Weights & Biases!\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sExKD5JHUGtc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('https://raw.githubusercontent.com/ChanceDurr/DS-Unit-4-Sprint-2-Neural-Networks/master/module4-Hyperparameter-Tuning/WA_Fn-UseC_-Telco-Customer-Churn.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOj9kki6WTLF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "ba61ccfa-88c6-4b93-ca7a-db9de806e5c5"
      },
      "source": [
        "# # Create a Fresh Experiment\n",
        "# wandb.init(project=\"hyperparameter_optimization_assignment\", entity=\"ds5\")\n",
        "\n",
        "# # Configure said Fresh Experiment\n",
        "# wandb.config.epochs = 50\n",
        "# wandb.config.batch_size = 20\n",
        "# wandb.config.hidden1_size = 20\n",
        "# wandb.config.hidden1_function = 'relu'\n",
        "# wandb.config.hidden2_size = 20\n",
        "# wandb.config.hidden2_function = 'relu'\n",
        "# wandb.config.hidden3_size = 20\n",
        "# wandb.config.hidden3_function = 'sigmoid'\n",
        "\n",
        "\n",
        "\n",
        "# Split Data into X and y\n",
        "X = df[['gender', 'SeniorCitizen', 'Partner', 'Dependents', 'tenure',\n",
        "       'PhoneService', 'MultipleLines', 'InternetService', 'OnlineSecurity', \n",
        "       'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV',\n",
        "       'StreamingMovies', 'Contract', 'PaperlessBilling', 'PaymentMethod']]\n",
        "\n",
        "y = df['Churn']\n",
        "\n",
        "\n",
        "# Encode Data with LabelEncoder\n",
        "encoder = LabelEncoder()\n",
        "\n",
        "X_encoded = X.apply(encoder.fit_transform)\n",
        "y_encoded = encoder.fit_transform(y)\n",
        "\n",
        "# Add data that didn't need encoded\n",
        "X_encoded['MonthlyCharges'] = df['MonthlyCharges']\n",
        "X_encoded['TotalCharges'] = df['TotalCharges']\n",
        "\n",
        "# Clean the TotalCharges column to replace missing values\n",
        "X_encoded['TotalCharges'] = X_encoded['TotalCharges'].replace(' ', '0')\n",
        "X_encoded['TotalCharges'] = X_encoded['TotalCharges'].astype('float')\n",
        "\n",
        "# Train/Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_encoded,\n",
        "                                                    y_encoded,\n",
        "                                                    test_size=0.33)\n",
        "\n",
        "\n",
        "\n",
        "# Create model wrapper\n",
        "def create_model(n_neurons = 20):\n",
        "  model = Sequential()\n",
        "\n",
        "  # Add Input Layer\n",
        "  model.add(Dense(n_neurons, activation='relu', input_shape=(X_train.shape[1],)))\n",
        "\n",
        "  # Add Hidden Layers\n",
        "  model.add(Dense(n_neurons, activation='relu'))\n",
        "  model.add(Dense(n_neurons, activation='relu'))\n",
        "\n",
        "  # Add Output Layer\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "  # Compile the model\n",
        "  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "  \n",
        "  return model\n",
        "\n",
        "# Create model\n",
        "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
        "\n",
        "# Define the grid search parameters\n",
        "param_grid = {'n_neurons': [15],\n",
        "              'batch_size': [30]}\n",
        "\n",
        "# Create Grid Search\n",
        "\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=2, cv=3)\n",
        "grid_result = grid.fit(X_train, y_train)\n",
        "\n",
        "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\") \n",
        "\n",
        "# Fit the model\n",
        "# model.fit(X_train, y_train,\n",
        "#           validation_data=(X_test, y_test),\n",
        "#           epochs=wandb.config.epochs,\n",
        "#           batch_size=wandb.config.batch_size,\n",
        "#           callbacks=[WandbCallback()])\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best: 0.740144130409446 using {'batch_size': 30, 'n_neurons': 15}\n",
            "Means: 0.740144130409446, Stdev: 0.0204998797939004 with: {'batch_size': 30, 'n_neurons': 15}\n",
            "Means: 0.625900807630566, Stdev: 0.16096278109569526 with: {'batch_size': 30, 'n_neurons': 16}\n",
            "Means: 0.6833404013164572, Stdev: 0.048568757698324895 with: {'batch_size': 30, 'n_neurons': 17}\n",
            "Means: 0.6634167041274237, Stdev: 0.14434097993269468 with: {'batch_size': 30, 'n_neurons': 18}\n",
            "Means: 0.739508266694569, Stdev: 0.011944822390407558 with: {'batch_size': 30, 'n_neurons': 19}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dy5TgCFOVs3m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "1b0fed77-a814-48d8-c03e-988858ed87aa"
      },
      "source": [
        "grid.best_estimator_.predict(X_test)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0],\n",
              "       [0],\n",
              "       [0],\n",
              "       ...,\n",
              "       [1],\n",
              "       [0],\n",
              "       [0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FfZRtJ7MCN3x"
      },
      "source": [
        "## Stretch Goals:\n",
        "\n",
        "- Try to implement Random Search Hyperparameter Tuning on this dataset\n",
        "- Try to implement Bayesian Optimiation tuning on this dataset using hyperas or hyperopt (if you're brave)\n",
        "- Practice hyperparameter tuning other datasets that we have looked at. How high can you get MNIST? Above 99%?\n",
        "- Study for the Sprint Challenge\n",
        " - Can you implement both perceptron and MLP models from scratch with forward and backpropagation?\n",
        " - Can you implement both perceptron and MLP models in keras and tune their hyperparameters with cross validation?"
      ]
    }
  ]
}